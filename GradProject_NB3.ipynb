{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1> DS200A Computer Vision Assignment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>  Part Three: Classifier training and performance assessment. </h2>\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = np.load('features_df.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def train_test_split(features_df):\n",
    "    #Normalize the features\n",
    "    #X = (features_df[:,:-1] - features_df[:,:-1].mean(axis=1)[:, np.newaxis])/features_df[:,:-1].std(axis=1)[:, np.newaxis]\n",
    "    X = features_df[:, :-1]\n",
    "    y = features_df[:,-1]\n",
    "    X, y = shuffle(X, y, random_state=0)\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X,y, train_size = 0.7, test_size=0.3)\n",
    "    return [X_train, X_test, y_train, y_test]\n",
    "#Split the data into a training set, and test set \n",
    "\n",
    "def accuracy(pred, actual):\n",
    "    return sum(pred == actual)/len(actual)\n",
    "# Calculate the accuracy percentage of the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv(model, X, y, k=10):\n",
    "    training_acc = 0\n",
    "    testing_acc = 0\n",
    "    cpt = 0\n",
    "    step = len(X)//k\n",
    "    for i in range(0,k):\n",
    "        if i==k-1:\n",
    "            X_test = X[i*step::]\n",
    "            y_test = y[i*step::]\n",
    "            X_train = X[0:i*step]\n",
    "            y_train = y[0:i*step]\n",
    "        else:\n",
    "            X_test = X[i*step:(i+1)*step]\n",
    "            y_test = y[i*step:(i+1)*step]\n",
    "            X_train = np.concatenate((X[0:i*step],X[(i+1)*step::]))\n",
    "            y_train = np.concatenate((y[0:i*step],y[(i+1)*step::]))\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        model_train_acc = model.evaluate(X_train, y_train)\n",
    "        training_acc += model_train_acc\n",
    "        model_test_acc = model.evaluate(X_test, y_test)\n",
    "        testing_acc += model_test_acc\n",
    "        print('Training {} of {}: - Training accuracy: {} - Testing accuracy: {}'.format(i+1, k, model_train_acc, model_test_acc))\n",
    "    print('\\nAverage Training Accuracy: {} / Average Testing Accuracy: {}'.format(training_acc/k, testing_acc/k))\n",
    "    return training_acc/k, testing_acc/k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>  Train models using all of the following methods below. Be sure to drop the actual image column, and the encoding</h3>\tTake note of the differences in accuracy, and methods.\n",
    "\n",
    "### For the following models, we used 5-fold cross validation to tune the hyper-parameters\n",
    "We could have used nested cross validation to avoid overfitting the test set when both selecting the hyper parameter and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.31042128603104213"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr = LogisticRegression(penalty='none', solver='lbfgs', multi_class='ovr')\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "logisticRegr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15521064301552107"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "neigh.fit(X_train, y_train)\n",
    "neigh.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22838137472283815"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf_tree = tree.DecisionTreeClassifier(max_depth = 10)\n",
    "clf_tree = clf_tree.fit(X_train, y_train)\n",
    "clf_tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.30155210643015523"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_randomforest = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "clf_randomforest.fit(X_train, y_train)\n",
    "clf_randomforest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21729490022172948"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf_svm = SVC(gamma='auto')\n",
    "clf_svm.fit(X_train, y_train)\n",
    "clf_svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta Classifier\n",
    "We are going to use the logistic regression classifier as well as the random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = np.concatenate((logisticRegr.predict(X_train).reshape(-1,1),clf_randomforest.predict(X_train).reshape(-1,1)), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_classifier = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "meta_classifier.fit(new_x, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2771618625277162"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x_test = np.concatenate((logisticRegr.predict(X_test).reshape(-1,1),clf_randomforest.predict(X_test).reshape(-1,1)), axis=1)\n",
    "meta_classifier.score(new_x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Prediction\n",
    "The meta classifier was less accurate than the random forest classifier. Let's train the random forest classifier with all the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = features_df[:,:-1]\n",
    "y = features_df[:,-1]\n",
    "clf_randomforest.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = {'Pictures':[], 'Names':[]}\n",
    "for image in glob.glob('20_Validation/*.jpg'):\n",
    "        testing_set['Names'].append(image.split('/')[1])\n",
    "        img = io.imread(image)\n",
    "        testing_set['Pictures'].append(img)\n",
    "testing_set = pd.DataFrame(testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pictures</th>\n",
       "      <th>Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[[[37, 37, 37], [35, 35, 35], [33, 33, 33], [3...</td>\n",
       "      <td>validation_pic (625).jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[[[255, 254, 255], [255, 254, 255], [255, 254,...</td>\n",
       "      <td>validation_pic (275).jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[[[9, 3, 13], [5, 0, 9], [3, 0, 7], [5, 0, 9],...</td>\n",
       "      <td>validation_pic (330).jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[[[64, 86, 48], [123, 143, 106], [124, 144, 10...</td>\n",
       "      <td>validation_pic (449).jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[[[159, 153, 141], [156, 150, 136], [145, 138,...</td>\n",
       "      <td>validation_pic (90).jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Pictures                     Names\n",
       "0  [[[37, 37, 37], [35, 35, 35], [33, 33, 33], [3...  validation_pic (625).jpg\n",
       "1  [[[255, 254, 255], [255, 254, 255], [255, 254,...  validation_pic (275).jpg\n",
       "2  [[[9, 3, 13], [5, 0, 9], [3, 0, 7], [5, 0, 9],...  validation_pic (330).jpg\n",
       "3  [[[64, 86, 48], [123, 143, 106], [124, 144, 10...  validation_pic (449).jpg\n",
       "4  [[[159, 153, 141], [156, 150, 136], [145, 138,...   validation_pic (90).jpg"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2gray\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "import cv2\n",
    "\n",
    "def ft1(image):\n",
    "    if len(image.shape) == 2: #if the image is in gray scale\n",
    "        return np.mean(image)\n",
    "    return np.mean(image[:,:,0])\n",
    "# Returns the average of the red-channel pictures for the images\n",
    "def ft3(image):\n",
    "    \"\"\"average of the blue-channel intensity - scalar feature\"\"\"\n",
    "    if len(image.shape) == 2:\n",
    "        return np.mean(image)\n",
    "    return np.mean(image[:,:,1])\n",
    "def ft4(image):\n",
    "    \"\"\"average of the green-channel intensity - scalar feature\"\"\"\n",
    "    if len(image.shape) == 2:\n",
    "        return np.mean(image)\n",
    "    return np.mean(image[:,:,2])\n",
    "def ft6(image):\n",
    "    \"\"\"Histogram of Oriented Gradients - vector feature\"\"\"\n",
    "    fd, _ = hog(resize(rgb2gray(image)), orientations=8, pixels_per_cell=(16, 16),\n",
    "                    cells_per_block=(1, 1), visualize=True)\n",
    "    return fd.reshape(1,-1)\n",
    "def ft7(image):\n",
    "    \"\"\"Mean intensity of image - scalar feature\"\"\"\n",
    "    return np.mean(rgb2gray(image))\n",
    "def ft11(image):\n",
    "    \"\"\"Total ratio of blue over other channels - scalar feature\"\"\"\n",
    "    return ft3(image) / (ft1(image)+ft4(image))\n",
    "def ft12(image):\n",
    "    \"\"\"returns black and white 30x30 image - vector feature\"\"\"\n",
    "    return resize(rgb2gray(image), (30,30)).reshape(1,-1)\n",
    "def ft14(image):\n",
    "    \"\"\"product of ratio of blue and mean image intensity\"\"\"\n",
    "    return np.log(ft11(image)+ft7(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(image, target_size=(40,40)):\n",
    "    \"\"\"\n",
    "    resizes image and adds zero padding so that it is 224*224\n",
    "    updates the bboxes (nparray) to match the new image\n",
    "    returns the new image as nparray and y_true as a dict 'classes' and 'bboxes' (nparray)\n",
    "    \"\"\"\n",
    "    ih, iw    = target_size\n",
    "    h,  w = image.shape[0], image.shape[1]\n",
    "\n",
    "    scale = min(iw/w, ih/h)\n",
    "    nw, nh  = int(scale * w), int(scale * h)\n",
    "    image_resized = cv2.resize(image, (nw, nh))\n",
    "    \n",
    "\n",
    "    image_paded = np.zeros((ih, iw))\n",
    "    dw, dh = (iw-nw) // 2, (ih-nh) // 2\n",
    "    image_paded[dh:nh+dh, dw:nw+dw] = image_resized #the original image is centered\n",
    "    image_paded = image_paded / 255.\n",
    "    return image_paded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_frame(df, features = [ft1, ft3, ft6, ft11, ft12, ft14]): #PLUS the Mixture of Gaussians Model\n",
    "    features_list = []\n",
    "    for feature in features:\n",
    "        ft = df.Pictures.apply(feature).values\n",
    "        if ft[0].shape == ():\n",
    "            features_list.append(ft[:, np.newaxis])\n",
    "        else:\n",
    "            features_list.append(np.concatenate(ft, axis=0))\n",
    "    new_df = np.concatenate(tuple(features_list), axis=1)\n",
    "    clf_GM = GaussianMixture(n_components = 20).fit(new_df)\n",
    "    return np.concatenate((new_df, clf_GM.predict(new_df)[:, np.newaxis]), axis=1)\n",
    "    #Returns data-frame with all the features now inside, and calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = feature_frame(testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf_randomforest.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set['Predictions'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set.drop(columns='Pictures').to_csv('predictions.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
